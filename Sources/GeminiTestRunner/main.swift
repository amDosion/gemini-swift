import Foundation
import gemini_swfit

class GeminiTestRunner {
    static func main() async {
        // æ£€æŸ¥çŽ¯å¢ƒå˜é‡
        guard let apiKey = ProcessInfo.processInfo.environment["GEMINI_API_KEY"] else {
            print("âŒ é”™è¯¯: è¯·è®¾ç½® GEMINI_API_KEY çŽ¯å¢ƒå˜é‡")
            print("   ä¾‹å¦‚: export GEMINI_API_KEY=your_api_key_here")
            return
        }
        
        print("ðŸš€ Gemini Swift Test Runner")
        print("==========================")
        print("\nè¯·é€‰æ‹©è¦è¿è¡Œçš„æµ‹è¯•:")
        print("1. åŸºç¡€æ–‡æœ¬ç”Ÿæˆæµ‹è¯•")
        print("2. å›¾ç‰‡ç†è§£æµ‹è¯•")
        print("3. å›¾ç‰‡åˆ†æžå®Œæ•´ç¤ºä¾‹")
        print("4. å¯¹è¯ç®¡ç†å™¨ç¤ºä¾‹")
        print("5. æœç´¢åŠŸèƒ½æµ‹è¯•")
        print("6. æ–‡æ¡£ä¸Šä¼ ç¤ºä¾‹")
        print("7. éŸ³é¢‘è¯†åˆ«æµ‹è¯•")
        print("8. å¢žå¼ºéŸ³é¢‘ç®¡ç†æµ‹è¯•")
        print("9. æµ‹è¯•æŒ‡å®šéŸ³é¢‘æ–‡ä»¶")
        print("10. è§†é¢‘ç†è§£æµ‹è¯•")
        print("11. è¿è¡Œæ‰€æœ‰æµ‹è¯•")
        print("\nè¯·è¾“å…¥é€‰é¡¹ (1-11): ", terminator: "")
        
        // è¯»å–ç”¨æˆ·è¾“å…¥
        let input = readLine()?.trimmingCharacters(in: .whitespacesAndNewlines)
        
        switch input {
        case "1":
            await runBasicTests(apiKey: apiKey)
        case "2":
            await runImageTests(apiKey: apiKey)
        case "3":
            await ImageAnalysisExample.main()
        case "4":
            await ConversationExample.main()
        case "5":
            await SearchExample.runAllExamples()
        case "6":
            await DocumentUploadExample.main()
        case "7":
            await runAudioTests(apiKey: apiKey)
        case "8":
            await runEnhancedAudioTests(apiKey: apiKey)
        case "9":
            await runSpecificAudioTest(apiKey: apiKey)
        case "10":
            await runVideoTests(apiKey: apiKey)
        case "11":
            await runBasicTests(apiKey: apiKey)
            print("\n" + "=" * 50)
            await runImageTests(apiKey: apiKey)
            print("\n" + "=" * 50)
            await ImageAnalysisExample.main()
            print("\n" + "=" * 50)
            await ConversationExample.main()
            print("\n" + "=" * 50)
            await SearchExample.runAllExamples()
            print("\n" + "=" * 50)
            await DocumentUploadExample.main()
            print("\n" + "=" * 50)
            await runAudioTests(apiKey: apiKey)
            print("\n" + "=" * 50)
            await runEnhancedAudioTests(apiKey: apiKey)
            print("\n" + "=" * 50)
            await runSpecificAudioTest(apiKey: apiKey)
            print("\n" + "=" * 50)
            await runVideoTests(apiKey: apiKey)
        default:
            print("æ— æ•ˆé€‰é¡¹ï¼Œè¿è¡ŒåŸºç¡€æµ‹è¯•...")
            await runBasicTests(apiKey: apiKey)
        }
    }
    
    static func runBasicTests(apiKey: String) async {
        print("\nðŸ”¤ åŸºç¡€æ–‡æœ¬ç”Ÿæˆæµ‹è¯•")
        print("====================")
        
        // Initialize the library
        GeminiSwift.initialize()
        
        // Create client with provided API key
        let client = GeminiClient(apiKey: apiKey)
        
        // Test 1: System Instruction (Cat example from curl)
        print("\n1. æµ‹è¯•ç³»ç»ŸæŒ‡ä»¤ - çŒ«å’ªè§’è‰²")
        print("-------------------------------")
        do {
            let response = try await client.generateText(
                model: .gemini25Flash,
                prompt: "Hello there",
                systemInstruction: "You are a cat. Your name is Neko."
            )
            print("âœ… å›žå¤: \(response)")
        } catch {
            print("âŒ é”™è¯¯: \(error)")
        }  
        
        // Test 2: Simple question without system instruction
        print("\n2. æµ‹è¯•ç®€å•é—®é¢˜")
        print("----------------")
        do {
            let response = try await client.generateText(
                model: .gemini25Flash,
                prompt: "What is 2+2?"
            )
            print("âœ… å›žå¤: \(response)")
        } catch {
            print("âŒ é”™è¯¯: \(error)")
        }
        
        // Test 3: With custom temperature
        print("\n3. æµ‹è¯•è‡ªå®šä¹‰æ¸©åº¦")
        print("------------------")
        do {
            let response = try await client.generateText(
                model: .gemini25Flash,
                prompt: "Tell me a joke",
                temperature: 0.9
            )
            print("âœ… å›žå¤: \(response)")
        } catch {
            print("âŒ é”™è¯¯: \(error)")
        }
        
        // Test 4: Different model
        print("\n4. æµ‹è¯• Gemini Pro")
        print("----------------")
        do {
            let response = try await client.generateText(
                model: .gemini25Pro,
                prompt: "Explain quantum computing in one sentence"
            )
            print("âœ… å›žå¤: \(response)")
        } catch {
            print("âŒ é”™è¯¯: \(error)")
        }
        
        print("\nðŸŽ‰ åŸºç¡€æ–‡æœ¬ç”Ÿæˆæµ‹è¯•å®Œæˆï¼")
    }
    
    static func runAudioTests(apiKey: String) async {
        print("\nðŸŽµ éŸ³é¢‘è¯†åˆ«æµ‹è¯•")
        print("================")
        
        // Initialize the library
        GeminiSwift.initialize()
        
        // Create client with provided API key
        let client = GeminiClient(apiKey: apiKey)
        let audioExample = AudioExample(client: client, apiKey: apiKey)
        
        print("\næ³¨æ„: æ­¤æµ‹è¯•éœ€è¦éŸ³é¢‘æ–‡ä»¶ã€‚è¯·ç¡®ä¿æœ‰ä»¥ä¸‹æ–‡ä»¶ä¹‹ä¸€:")
        print("- sample.mp3, sample.wav, audio.m4a (åœ¨ Resources ç›®å½•)")
        print("- /tmp/sample.mp3")
        print("- /Users/Shared/sample.mp3")
        
        await audioExample.runAudioTranscriptionExample()
        await audioExample.runAudioAnalysisExample()
        await audioExample.runBatchAudioUploadExample()
        
        print("\nðŸŽ‰ éŸ³é¢‘è¯†åˆ«æµ‹è¯•å®Œæˆï¼")
    }
    
    static func runEnhancedAudioTests(apiKey: String) async {
        print("\nðŸš€ å¢žå¼ºéŸ³é¢‘ç®¡ç†æµ‹è¯•")
        print("==================")
        
        // Initialize the library
        GeminiSwift.initialize()
        
        // Create client with provided API key
        let client = GeminiClient(apiKey: apiKey)
        
        print("\næ³¨æ„: æ­¤æµ‹è¯•éœ€è¦å¤šä¸ªéŸ³é¢‘æ–‡ä»¶ã€‚è¯·ç¡®ä¿æœ‰ä»¥ä¸‹æ–‡ä»¶:")
        print("- /tmp/sample1.mp3, /tmp/sample2.mp3, /tmp/sample3.mp3")
        print("- /Users/Shared/audio1.mp3, /Users/Shared/audio2.mp3")
        
        let example = EnhancedAudioExample(client: client, apiKey: apiKey)
        
        await example.runEnhancedBatchExample()
        await example.runSmartSchedulingExample()
        await example.runKeyOptimizationExample()
        await example.runRetryMechanismExample()
        
        print("\nðŸŽ‰ å¢žå¼ºéŸ³é¢‘ç®¡ç†æµ‹è¯•å®Œæˆï¼")
    }
    
    static func runSpecificAudioTest(apiKey: String) async {
        print("\nðŸŽµ æµ‹è¯•æŒ‡å®šéŸ³é¢‘æ–‡ä»¶")
        print("===================")
        
        // Initialize the library
        GeminiSwift.initialize()
        
        // Create client with provided API key
        let client = GeminiClient(apiKey: apiKey)
        
        // Test with specific audio file
        let test = AudioTest(client: client, apiKey: apiKey)
        await test.runAudioTests()
    }
    
    static func runImageTests(apiKey: String) async {
        print("\nðŸ–¼ï¸ å›¾ç‰‡ç†è§£æµ‹è¯•")
        print("==================")
        
        // Initialize the library
        GeminiSwift.initialize()
        
        // Create client with provided API key
        let client = GeminiClient(apiKey: apiKey)
        
        // Test 1: Use existing test image
        print("\n1. æµ‹è¯•ç®€å•å›¾ç‰‡åˆ†æž - ä½¿ç”¨çŽ°æœ‰å›¾ç‰‡")
        print("------------------------------------")
        
        do {
            // Load the existing test image
            guard let imagePath = Bundle.main.path(forResource: "image", ofType: "png") else {
                print("âŒ é”™è¯¯: æ‰¾ä¸åˆ°æµ‹è¯•å›¾ç‰‡æ–‡ä»¶")
                return
            }
            let imageData = try Data(contentsOf: URL(fileURLWithPath: imagePath))
            
            let response = try await client.analyzeImage(
                model: .gemini25Flash,
                prompt: "What do you see in this image? Describe the colors and shape.",
                imageData: imageData,
                mimeType: "image/png"
            )
            print("âœ… å›¾ç‰‡åˆ†æžç»“æžœ: \(response)")
        } catch {
            print("âŒ é”™è¯¯: \(error)")
        }
        
        // Test 2: Test with different models
        print("\n2. æµ‹è¯•ä¸åŒæ¨¡åž‹çš„å›¾ç‰‡ç†è§£èƒ½åŠ›")
        print("--------------------------------")
        
        do {
            // Load the existing test image
            guard let imagePath = Bundle.main.path(forResource: "image", ofType: "png") else {
                print("âŒ é”™è¯¯: æ‰¾ä¸åˆ°æµ‹è¯•å›¾ç‰‡æ–‡ä»¶")
                return
            }
            let imageData = try Data(contentsOf: URL(fileURLWithPath: imagePath))
            
            // Test with Flash Image Preview model
            let response = try await client.analyzeImage(
                model: .gemini25FlashImagePreview,
                prompt: "Analyze this image in detail. What patterns, colors, and shapes do you see?",
                imageData: imageData,
                mimeType: "image/png"
            )
            print("âœ… Flash Image Preview åˆ†æž: \(response)")
        } catch {
            print("âŒ é”™è¯¯: \(error)")
        }
        
        // Test 3: Multi-turn conversation with image
        print("\n3. æµ‹è¯•å›¾ç‰‡+å¯¹è¯ç»„åˆ")
        print("--------------------")
        
        do {
            // Load the existing test image
            guard let imagePath = Bundle.main.path(forResource: "image", ofType: "png") else {
                print("âŒ é”™è¯¯: æ‰¾ä¸åˆ°æµ‹è¯•å›¾ç‰‡æ–‡ä»¶")
                return
            }
            let imageData = try Data(contentsOf: URL(fileURLWithPath: imagePath))
            var history: [Content] = []
            
            // First message with image
            let response1 = try await client.sendMessage(
                model: .gemini25Flash,
                message: "Please describe this image",
                history: history
            )
            
            // Add the multimodal message to history manually
            history.append(Content.multimodalMessage(text: "Please describe this image", imageData: imageData))
            history.append(Content.modelMessage(response1.candidates.first?.content.parts.first?.text ?? ""))
            
            print("âœ… ç¬¬ä¸€è½®å¯¹è¯: \(response1.candidates.first?.content.parts.first?.text ?? "")")
            
            // Follow-up question without image
            let response2 = try await client.sendMessage(
                model: .gemini25Flash,
                message: "What would be a good use case for this type of image?",
                history: history
            )
            
            print("âœ… ç¬¬äºŒè½®å¯¹è¯: \(response2.candidates.first?.content.parts.first?.text ?? "")")
            
        } catch {
            print("âŒ é”™è¯¯: \(error)")
        }
        
        print("\nðŸŽ‰ å›¾ç‰‡ç†è§£æµ‹è¯•å®Œæˆï¼")
    }
    
    static func runVideoTests(apiKey: String) async {
        print("\nðŸŽ¥ è§†é¢‘ç†è§£æµ‹è¯•")
        print("==================")
        
        // Initialize the library
        GeminiSwift.initialize()
        
        // Create video example instance
        let videoExample = VideoExample(apiKey: apiKey)
        
        // Run examples
        await videoExample.runExamples()
    }
    
}

// MARK: - è¾…åŠ©æ‰©å±•

extension String {
    static func *(left: String, right: Int) -> String {
        return String(repeating: left, count: right)
    }
}

Task {
    await GeminiTestRunner.main()
}

// Keep the program running
RunLoop.main.run(until: Date(timeIntervalSinceNow: 60))